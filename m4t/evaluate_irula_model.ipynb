{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5ac3d7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#@title Irula-Malayalam Model Evaluation\n",
    "MAX_SAMPLES = 100 # @param {type:\"number\"}\n",
    "CHECKPOINT_PATH = \"checkpoints/ft_gs_m4tM.pt\" # @param {type:\"string\"}\n",
    "EVAL_MANIFEST = \"manifests/valid_manifest.json\" # @param {type:\"string\"}\n",
    "CSV_PATH = \"lama.csv\" # @param {type:\"string\"}\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from typing import Tuple, Iterable, Dict, Any\n",
    "from seamless_communication.models.unity import UnitYModel\n",
    "from seamless_communication.inference import Translator\n",
    "from jiwer import wer, cer\n",
    "\n",
    "def load_text_data(csv_path: str) -> Dict[str, Dict[str, str]]:\n",
    "    \"\"\"Load text data from CSV file\"\"\"\n",
    "    print(\"Loading text data from CSV...\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    id_to_text = {}\n",
    "    for _, row in df.iterrows():\n",
    "        file_id = str(row['id of speech and text'])\n",
    "        \n",
    "        # Handle NaN values\n",
    "        irula_val = row['Irula text']\n",
    "        malayalam_val = row['Malayalam text']\n",
    "        \n",
    "        irula_text = str(irula_val) if not pd.isna(irula_val) and str(irula_val).strip() != '' else \"\"\n",
    "        malayalam_text = str(malayalam_val) if not pd.isna(malayalam_val) and str(malayalam_val).strip() != '' else \"\"\n",
    "        \n",
    "        id_to_text[file_id] = {\n",
    "            'irula': irula_text,\n",
    "            'malayalam': malayalam_text\n",
    "        }\n",
    "    \n",
    "    print(f\"Loaded text data for {len(id_to_text)} entries\")\n",
    "    return id_to_text\n",
    "\n",
    "def _iterate_irula_dataset(manifest_path: str, text_data: Dict) -> Iterable[Tuple[torch.Tensor, str, str]]:\n",
    "    \"\"\"Iterate over Irula-Malayalam dataset from manifest\"\"\"\n",
    "    print(f\"Loading evaluation data from {manifest_path}...\")\n",
    "    \n",
    "    with open(manifest_path, 'r', encoding='utf-8') as f:\n",
    "        count = 0\n",
    "        for line in f:\n",
    "            if count >= MAX_SAMPLES:\n",
    "                break\n",
    "                \n",
    "            sample = json.loads(line.strip())\n",
    "            \n",
    "            # Get source audio path (Malayalam)\n",
    "            src_audio_path = sample['source']['audio_local_path']\n",
    "            file_id = sample['source']['id']\n",
    "            \n",
    "            try:\n",
    "                # Load source audio (Malayalam)\n",
    "                audio, sr = librosa.load(src_audio_path, sr=16000, mono=True)\n",
    "                assert sr == 16000, f\"Audio must be 16kHz, got {sr}Hz\"\n",
    "                audio_tensor = torch.from_numpy(audio)\n",
    "                \n",
    "                # Get texts\n",
    "                malayalam_text = sample['source'].get('text', '')\n",
    "                irula_text = sample['target'].get('text', '')\n",
    "                \n",
    "                # Fallback to CSV data if not in manifest\n",
    "                if not malayalam_text or not irula_text:\n",
    "                    if file_id in text_data:\n",
    "                        malayalam_text = text_data[file_id]['malayalam']\n",
    "                        irula_text = text_data[file_id]['irula']\n",
    "                \n",
    "                if malayalam_text and irula_text:\n",
    "                    yield audio_tensor, malayalam_text, irula_text\n",
    "                    count += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading audio {src_audio_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "def eval_speech_to_text(translator: Translator, text_data: Dict) -> Tuple[float, float]:\n",
    "    \"\"\"Evaluate Speech-to-Text (Malayalam speech -> Irula text)\"\"\"\n",
    "    references = []\n",
    "    predictions = []\n",
    "    \n",
    "    ds = _iterate_irula_dataset(EVAL_MANIFEST, text_data)\n",
    "    \n",
    "    for idx, (wav, malayalam_text, irula_text) in tqdm(enumerate(ds), desc=\"S2T Evaluation\"):\n",
    "        if not irula_text.strip():\n",
    "            continue\n",
    "            \n",
    "        references.append(irula_text)\n",
    "        \n",
    "        try:\n",
    "            # Malayalam speech -> Irula text\n",
    "            prediction = translator.predict(\n",
    "                input=wav,\n",
    "                task_str=\"s2tt\",  # Speech-to-Text\n",
    "                src_lang=\"mal\",   # Malayalam\n",
    "                tgt_lang=\"mal\",   # Irula (you might need to use \"und\" if \"iru\" is not supported)\n",
    "            )\n",
    "            \n",
    "            if prediction and len(prediction) > 0:\n",
    "                predicted_text = str(prediction[0][0])\n",
    "            else:\n",
    "                predicted_text = \"\"\n",
    "                \n",
    "            predictions.append(predicted_text)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in S2T prediction: {e}\")\n",
    "            predictions.append(\"\")\n",
    "    \n",
    "    if predictions and references:\n",
    "        wer_score = wer(reference=references, hypothesis=predictions)\n",
    "        cer_score = cer(reference=references, hypothesis=predictions)\n",
    "        return wer_score, cer_score\n",
    "    else:\n",
    "        return 1.0, 1.0\n",
    "\n",
    "def eval_speech_to_speech(translator: Translator, text_data: Dict) -> Tuple[float, float]:\n",
    "    \"\"\"Evaluate Speech-to-Speech (Malayalam speech -> Irula speech, compare transcripts)\"\"\"\n",
    "    references = []\n",
    "    predictions = []\n",
    "    \n",
    "    ds = _iterate_irula_dataset(EVAL_MANIFEST, text_data)\n",
    "    \n",
    "    for idx, (wav, malayalam_text, irula_text) in tqdm(enumerate(ds), desc=\"S2S Evaluation\"):\n",
    "        if not irula_text.strip():\n",
    "            continue\n",
    "            \n",
    "        references.append(irula_text)\n",
    "        \n",
    "        try:\n",
    "            # Malayalam speech -> Irula speech (we'll evaluate the text content)\n",
    "            prediction = translator.predict(\n",
    "                input=wav,\n",
    "                task_str=\"s2tt\",  # Speech-to-Speech\n",
    "                src_lang=\"mal\",   # Malayalam\n",
    "                tgt_lang=\"mal\",   # Irula\n",
    "            )\n",
    "            \n",
    "            # For S2ST, we need to get the text from the generated speech\n",
    "            # This is a simplified version - you might need to use ASR on the output\n",
    "            if prediction and len(prediction) > 0:\n",
    "                predicted_text = str(prediction[0][0])  # This might need adjustment\n",
    "            else:\n",
    "                predicted_text = \"\"\n",
    "                \n",
    "            predictions.append(predicted_text)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in S2S prediction: {e}\")\n",
    "            predictions.append(\"\")\n",
    "    \n",
    "    if predictions and references:\n",
    "        wer_score = wer(reference=references, hypothesis=predictions)\n",
    "        cer_score = cer(reference=references, hypothesis=predictions)\n",
    "        return wer_score, cer_score\n",
    "    else:\n",
    "        return 1.0, 1.0\n",
    "\n",
    "def load_checkpoint(model: UnitYModel, path: str, device=\"cuda\") -> None:\n",
    "    \"\"\"Load checkpoint with better error handling\"\"\"\n",
    "    print(f\"Loading checkpoint from {path}...\")\n",
    "    \n",
    "    try:\n",
    "        state_dict = torch.load(path, map_location=device)[\"model\"]\n",
    "\n",
    "        def _select_keys(state_dict: Dict[str, Any], prefix: str) -> Dict[str, Any]:\n",
    "            return {key.replace(prefix, \"\"): value for key, value in state_dict.items() if key.startswith(prefix)}\n",
    "\n",
    "        model.speech_encoder_frontend.load_state_dict(_select_keys(state_dict, \"model.speech_encoder_frontend.\"))\n",
    "        model.speech_encoder.load_state_dict(_select_keys(state_dict, \"model.speech_encoder.\"))\n",
    "\n",
    "        if model.text_decoder_frontend is not None:\n",
    "            model.text_decoder_frontend.load_state_dict(_select_keys(state_dict, \"model.text_decoder_frontend.\"))\n",
    "\n",
    "        if model.text_decoder is not None:\n",
    "            model.text_decoder.load_state_dict(_select_keys(state_dict, \"model.text_decoder.\"))\n",
    "        \n",
    "        print(\"Checkpoint loaded successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading checkpoint: {e}\")\n",
    "        raise\n",
    "\n",
    "# Check if required files exist\n",
    "if not os.path.exists(EVAL_MANIFEST):\n",
    "    print(f\"Error: Evaluation manifest not found at {EVAL_MANIFEST}\")\n",
    "    print(\"Please run your manifest creation script first.\")\n",
    "else:\n",
    "    # Load text data\n",
    "    text_data = load_text_data(CSV_PATH)\n",
    "    \n",
    "    # Initialize translator\n",
    "    print(\"Initializing translator...\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    translator = Translator(\n",
    "        model_name_or_card=\"seamlessM4T_v2_large\",\n",
    "        vocoder_name_or_card=None,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Evaluate base model\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"EVALUATING BASE MODEL\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    try:\n",
    "        base_s2t_wer, base_s2t_cer = eval_speech_to_text(translator, text_data)\n",
    "        print(f\"Base Model S2T - WER: {base_s2t_wer:.4f}, CER: {base_s2t_cer:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in base S2T evaluation: {e}\")\n",
    "        base_s2t_wer, base_s2t_cer = 1.0, 1.0\n",
    "    \n",
    "    try:\n",
    "        base_s2s_wer, base_s2s_cer = eval_speech_to_speech(translator, text_data)\n",
    "        print(f\"Base Model S2S - WER: {base_s2s_wer:.4f}, CER: {base_s2s_cer:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in base S2S evaluation: {e}\")\n",
    "        base_s2s_wer, base_s2s_cer = 1.0, 1.0\n",
    "    \n",
    "    # Load and evaluate fine-tuned model\n",
    "    if os.path.exists(CHECKPOINT_PATH):\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"EVALUATING FINE-TUNED MODEL\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        try:\n",
    "            load_checkpoint(translator.model, CHECKPOINT_PATH, device)\n",
    "            \n",
    "            tuned_s2t_wer, tuned_s2t_cer = eval_speech_to_text(translator, text_data)\n",
    "            print(f\"Fine-tuned S2T - WER: {tuned_s2t_wer:.4f}, CER: {tuned_s2t_cer:.4f}\")\n",
    "            \n",
    "            tuned_s2s_wer, tuned_s2s_cer = eval_speech_to_speech(translator, text_data)\n",
    "            print(f\"Fine-tuned S2S - WER: {tuned_s2s_wer:.4f}, CER: {tuned_s2s_cer:.4f}\")\n",
    "            \n",
    "            # Calculate improvements\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"IMPROVEMENT SUMMARY\")\n",
    "            print(\"=\"*50)\n",
    "            print(f\"S2T WER Improvement: {base_s2t_wer - tuned_s2t_wer:.4f}\")\n",
    "            print(f\"S2T CER Improvement: {base_s2t_cer - tuned_s2t_cer:.4f}\")\n",
    "            print(f\"S2S WER Improvement: {base_s2s_wer - tuned_s2s_wer:.4f}\")\n",
    "            print(f\"S2S CER Improvement: {base_s2s_cer - tuned_s2s_cer:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error with fine-tuned model: {e}\")\n",
    "    else:\n",
    "        print(f\"\\nCheckpoint not found at {CHECKPOINT_PATH}\")\n",
    "        print(\"Only base model evaluation performed.\")\n",
    "    \n",
    "    # Clear CUDA memory\n",
    "    del translator\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(\"\\nEvaluation completed!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
